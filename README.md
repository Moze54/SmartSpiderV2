# SmartSpider - æ™ºèƒ½çˆ¬è™«å·¥å…·

SmartSpider æ˜¯ä¸€ä¸ªåŸºäº FastAPI çš„é«˜æ€§èƒ½å¼‚æ­¥çˆ¬è™«å·¥å…·ï¼Œä¸“ä¸ºå¼€å‘è€…è®¾è®¡ï¼Œé€šè¿‡ç®€å•çš„ REST API æ¥å£å³å¯å®ç°å¼ºå¤§çš„ç½‘é¡µçˆ¬å–åŠŸèƒ½ã€‚

## ğŸš€ é¡¹ç›®ç‰¹æ€§

- **å¼‚æ­¥é«˜æ€§èƒ½**: åŸºäº asyncio å’Œ aiohttp å®ç°é«˜å¹¶å‘çˆ¬å–
- **RESTful API**: æä¾›å®Œæ•´çš„ HTTP API æ¥å£ï¼Œæ˜“äºé›†æˆ
- **çµæ´»é…ç½®**: æ”¯æŒ CSS é€‰æ‹©å™¨å’Œ XPath è¡¨è¾¾å¼è¿›è¡Œæ•°æ®æå–
- **ä»»åŠ¡ç®¡ç†**: æ”¯æŒä»»åŠ¡çš„åˆ›å»ºã€å¯åŠ¨ã€åœæ­¢ã€åˆ é™¤ç­‰å…¨ç”Ÿå‘½å‘¨æœŸç®¡ç†
- **é”™è¯¯å¤„ç†**: å®Œå–„çš„å¼‚å¸¸å¤„ç†æœºåˆ¶ï¼Œæä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
- **æ•°æ®åº“æ”¯æŒ**: ä½¿ç”¨ MySQL å­˜å‚¨ä»»åŠ¡å’Œç»“æœæ•°æ®
- **æµ‹è¯•è¦†ç›–**: åŒ…å«å®Œæ•´çš„å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•

## ğŸ“‹ åŠŸèƒ½æ¸…å•

### æ ¸å¿ƒåŠŸèƒ½
- [x] ç½‘é¡µå†…å®¹çˆ¬å–
- [x] æ•°æ®è§£ææå–
- [x] ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸç®¡ç†
- [x] é…ç½®ç®¡ç†
- [x] é”™è¯¯å¤„ç†ä¸é‡è¯•æœºåˆ¶
- [x] ç»“æœå­˜å‚¨ä¸æŸ¥è¯¢

### API æ¥å£
- [x] ä»»åŠ¡åˆ›å»ºä¸ç®¡ç†
- [x] ä»»åŠ¡çŠ¶æ€æŸ¥è¯¢
- [x] çˆ¬å–ç»“æœè·å–
- [x] å¥åº·æ£€æŸ¥
- [x] å¿«é€Ÿå¯åŠ¨ä»»åŠ¡

### æŠ€æœ¯ç‰¹æ€§
- [x] å¼‚æ­¥éé˜»å¡ I/O
- [x] å¹¶å‘æ§åˆ¶
- [x] ä»£ç†æ”¯æŒ
- [x] é€Ÿç‡é™åˆ¶
- [x] è¶…æ—¶å¤„ç†
- [x] æ—¥å¿—è®°å½•

## ğŸ› ï¸ æŠ€æœ¯æ ˆ

- **åç«¯æ¡†æ¶**: FastAPI (åŸºäº Starlette å’Œ Pydantic)
- **å¼‚æ­¥ HTTP**: aiohttp
- **æ•°æ®åº“**: MySQL + SQLAlchemy (å¼‚æ­¥æ”¯æŒ)
- **HTML è§£æ**: BeautifulSoup4 + lxml
- **é…ç½®ç®¡ç†**: Pydantic Settings
- **æµ‹è¯•æ¡†æ¶**: pytest + httpx
- **éƒ¨ç½²**: uvicorn

## ğŸ“¦ å®‰è£…ä¸é…ç½®

### ç¯å¢ƒè¦æ±‚

- Python 3.8+
- MySQL 5.7+

### å®‰è£…æ­¥éª¤

1. **å…‹éš†é¡¹ç›®**
   ```bash
   git clone https://github.com/your-repo/smartspider.git
   cd smartspider
   ```

2. **åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/Mac
   # æˆ–
   venv\Scripts\activate  # Windows
   ```

3. **å®‰è£…ä¾èµ–**
   ```bash
   pip install -r requirements.txt
   ```

4. **é…ç½®ç¯å¢ƒå˜é‡**
   ```bash
   cp .env.example .env
   # ç¼–è¾‘ .env æ–‡ä»¶ï¼Œé…ç½®æ•°æ®åº“è¿æ¥ç­‰ä¿¡æ¯
   ```

5. **åˆå§‹åŒ–æ•°æ®åº“**
   ```bash
   python init_db.py
   ```

6. **å¯åŠ¨æœåŠ¡**
   ```bash
   python run.py
   ```

## âš™ï¸ é…ç½®è¯´æ˜

### æ•°æ®åº“é…ç½®

åœ¨ `.env` æ–‡ä»¶ä¸­é…ç½®æ•°æ®åº“è¿æ¥ï¼š

```env
# æ•°æ®åº“é…ç½®
DB_HOST=localhost
DB_PORT=3306
DB_USER=your_user
DB_PASSWORD=your_password
DB_NAME=smartspider
```

### åº”ç”¨é…ç½®

åº”ç”¨é…ç½®ä½äº `smart_spider/config/crawler_config.py` ä¸­ï¼Œæ”¯æŒä»¥ä¸‹é…ç½®é¡¹ï¼š

- **å¹¶å‘æ§åˆ¶**: max_concurrent_requests, request_delay
- **è¶…æ—¶è®¾ç½®**: timeout, retry_times, retry_delay
- **ç”¨æˆ·ä»£ç†**: user_agent
- **ä»£ç†è®¾ç½®**: proxies, proxy_rotation
- **æ•°æ®æå–**: selector_type (css/xpath), parse_rules

## ğŸ¯ å¿«é€Ÿå¼€å§‹

### 1. åˆ›å»ºçˆ¬è™«ä»»åŠ¡

```bash
curl -X POST "http://localhost:8000/api/v1/tasks" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "ç¤ºä¾‹ä»»åŠ¡",
    "description": "çˆ¬å–ç¤ºä¾‹ç½‘ç«™",
    "urls": ["https://example.com"],
    "parse_rules": {
      "title": "h1",
      "links": "a"
    },
    "selector_type": "css"
  }'
```

### 2. å¯åŠ¨ä»»åŠ¡

```bash
curl -X POST "http://localhost:8000/api/v1/tasks/{task_id}/start"
```

### 3. æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€

```bash
curl "http://localhost:8000/api/v1/tasks/{task_id}/status"
```

### 4. è·å–çˆ¬å–ç»“æœ

```bash
curl "http://localhost:8000/api/v1/tasks/{task_id}/results"
```

### 5. å¿«é€Ÿå¯åŠ¨ï¼ˆä¸€æ­¥å®Œæˆï¼‰

```bash
curl -X POST "http://localhost:8000/api/v1/tasks/quick-start" \
  -H "Content-Type: application/json" \
  -d '{
    "url": "https://example.com",
    "parse_rules": {"title": "h1", "content": ".content"}
  }'
```

## ğŸ“– API æ–‡æ¡£

### ä»»åŠ¡ç®¡ç†æ¥å£

#### åˆ›å»ºä»»åŠ¡
```http
POST /api/v1/tasks
```

**è¯·æ±‚ä½“ç¤ºä¾‹ï¼š**
```json
{
  "name": "ä»»åŠ¡åç§°",
  "description": "ä»»åŠ¡æè¿°",
  "urls": ["https://example.com"],
  "parse_rules": {
    "title": "h1",
    "content": ".content"
  },
  "max_concurrent_requests": 5,
  "request_delay": 1.0,
  "timeout": 30,
  "retry_times": 3,
  "selector_type": "css"
}
```

#### ä»»åŠ¡æ“ä½œ
- `POST /api/v1/tasks/{task_id}/start` - å¯åŠ¨ä»»åŠ¡
- `POST /api/v1/tasks/{task_id}/stop` - åœæ­¢ä»»åŠ¡
- `DELETE /api/v1/tasks/{task_id}` - åˆ é™¤ä»»åŠ¡
- `GET /api/v1/tasks/{task_id}` - è·å–ä»»åŠ¡è¯¦æƒ…
- `GET /api/v1/tasks/{task_id}/results` - è·å–çˆ¬å–ç»“æœ
- `GET /api/v1/tasks/{task_id}/status` - è·å–ä»»åŠ¡çŠ¶æ€

#### ä»»åŠ¡åˆ—è¡¨
```http
GET /api/v1/tasks?status=PENDING&limit=10&offset=0
```

## ğŸ§ª æµ‹è¯•

é¡¹ç›®åŒ…å«å®Œæ•´çš„æµ‹è¯•å¥—ä»¶ï¼š

### è¿è¡Œæ‰€æœ‰æµ‹è¯•
```bash
pytest tests/ -v
```

### è¿è¡Œç‰¹å®šæµ‹è¯•
```bash
pytest tests/test_api.py -v
pytest tests/test_crawler_config.py -v
pytest tests/test_downloader.py -v
pytest tests/test_parser.py -v
```

### ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
```bash
pytest tests/ --cov=smart_spider --cov-report=html
```

## ğŸ“Š é¡¹ç›®ç»“æ„

```
smartspider/
â”œâ”€â”€ smart_spider/               # ä¸»é¡¹ç›®ç›®å½•
â”‚   â”œâ”€â”€ api/                   # API æ¥å£
â”‚   â”‚   â”œâ”€â”€ routes.py         # è·¯ç”±å®šä¹‰
â”‚   â”‚   â””â”€â”€ schemas.py        # æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ config/               # é…ç½®ç®¡ç†
â”‚   â”‚   â””â”€â”€ crawler_config.py
â”‚   â”œâ”€â”€ core/                 # æ ¸å¿ƒç»„ä»¶
â”‚   â”‚   â”œâ”€â”€ database.py       # æ•°æ®åº“è¿æ¥
â”‚   â”‚   â”œâ”€â”€ exceptions.py     # å¼‚å¸¸å®šä¹‰
â”‚   â”‚   â””â”€â”€ logger.py         # æ—¥å¿—é…ç½®
â”‚   â”œâ”€â”€ engine/               # çˆ¬è™«å¼•æ“
â”‚   â”‚   â”œâ”€â”€ crawler.py        # ä¸»çˆ¬è™«å¼•æ“
â”‚   â”‚   â”œâ”€â”€ downloader.py     # ä¸‹è½½å™¨
â”‚   â”‚   â””â”€â”€ parser.py         # è§£æå™¨
â”‚   â”œâ”€â”€ models/               # æ•°æ®æ¨¡å‹
â”‚   â”‚   â””â”€â”€ database.py       # æ•°æ®åº“æ¨¡å‹
â”‚   â”œâ”€â”€ services/             # ä¸šåŠ¡æœåŠ¡
â”‚   â”‚   â””â”€â”€ task_service.py   # ä»»åŠ¡æœåŠ¡
â”‚   â””â”€â”€ main.py               # FastAPI åº”ç”¨
â”œâ”€â”€ tests/                    # æµ‹è¯•ç›®å½•
â”‚   â”œâ”€â”€ conftest.py          # æµ‹è¯•é…ç½®
â”‚   â”œâ”€â”€ test_api.py          # API æµ‹è¯•
â”‚   â”œâ”€â”€ test_crawler_config.py
â”‚   â”œâ”€â”€ test_downloader.py
â”‚   â””â”€â”€ test_parser.py
â”œâ”€â”€ logs/                     # æ—¥å¿—ç›®å½•
â”œâ”€â”€ output/                   # è¾“å‡ºç›®å½•
â”œâ”€â”€ init_db.py               # æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬
â”œâ”€â”€ run.py                   # å¯åŠ¨è„šæœ¬
â”œâ”€â”€ requirements.txt         # ä¾èµ–åˆ—è¡¨
â””â”€â”€ README.md               # é¡¹ç›®æ–‡æ¡£
```

## ğŸ”§ é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰é€‰æ‹©å™¨

æ”¯æŒ CSS é€‰æ‹©å™¨å’Œ XPath è¡¨è¾¾å¼ï¼š

```json
{
  "parse_rules": {
    "title": "h1.title",
    "price": ".price::text",
    "description": "//div[@class='description']/p/text()",
    "links": "a[href]"
  },
  "selector_type": "css"
}
```

### ä»£ç†é…ç½®

```json
{
  "crawler": {
    "proxies": [
      "http://proxy1:8080",
      "http://proxy2:8080"
    ],
    "proxy_rotation": true
  }
}
```

### é€Ÿç‡é™åˆ¶

```json
{
  "crawler": {
    "max_concurrent_requests": 5,
    "request_delay": 1.0,
    "timeout": 30,
    "retry_times": 3
  }
}
```

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æ•°æ®åº“è¿æ¥å¤±è´¥**
   - æ£€æŸ¥ MySQL æœåŠ¡æ˜¯å¦è¿è¡Œ
   - ç¡®è®¤æ•°æ®åº“ç”¨æˆ·æƒé™
   - éªŒè¯è¿æ¥å‚æ•°é…ç½®

2. **çˆ¬å–è¶…æ—¶**
   - å¢åŠ  timeout é…ç½®å€¼
   - æ£€æŸ¥ç½‘ç»œè¿æ¥
   - å¯ç”¨ä»£ç†æˆ– VPN

3. **å†…å­˜ä¸è¶³**
   - å‡å°‘ max_concurrent_requests
   - åˆ†æ‰¹å¤„ç†å¤§é‡ URL
   - å®šæœŸæ¸…ç†ä»»åŠ¡ç»“æœ

### æ—¥å¿—æŸ¥çœ‹

æ—¥å¿—æ–‡ä»¶ä½äº `logs/` ç›®å½•ï¼š
- `app.log` - åº”ç”¨æ—¥å¿—
- `crawler.log` - çˆ¬è™«å¼•æ“æ—¥å¿—
- `error.log` - é”™è¯¯æ—¥å¿—

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

---

**SmartSpider** - è®©æ•°æ®çˆ¬å–å˜å¾—ç®€å•è€Œå¼ºå¤§ï¼